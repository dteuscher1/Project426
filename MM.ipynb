{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "hustle = pd.read_csv('model_data.csv')\n",
    "hustle['WINNER_cat'] = hustle['WINNER'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "away = hustle.iloc[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = hustle[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hr = home[['DEFLECTIONS_RATIO', 'CONTEST_RATE', 'CONTEST_RATE_2', 'CONTEST_RATE_3', 'CHARGES_RATIO', 'SCREEN_AST_RATIO', 'SCREEN_AST_PTS_RATIO', 'LOOSE_RATIO', 'OFF_BOXOUT_RATIO', 'DEF_BOXOUT_RATIO', 'BOXOUT_TM_RBS_RATIO']].values\n",
    "y_hr = home['WINNER'].values\n",
    "\n",
    "X_hr_train, X_hr_test, y_hr_train, y_hr_test = train_test_split(X_hr, y_hr, stratify = y_hr, random_state = 858, test_size = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ar = away[['DEFLECTIONS_RATIO', 'CONTEST_RATE', 'CONTEST_RATE_2', 'CONTEST_RATE_3', 'CHARGES_RATIO', 'SCREEN_AST_RATIO', 'SCREEN_AST_PTS_RATIO', 'LOOSE_RATIO', 'OFF_BOXOUT_RATIO', 'DEF_BOXOUT_RATIO', 'BOXOUT_TM_RBS_RATIO']].values\n",
    "y_ar = away['WINNER'].values\n",
    "\n",
    "X_ar_train, X_ar_test, y_ar_train, y_ar_test = train_test_split(X_ar, y_ar, stratify = y_ar, random_state = 858, test_size = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hd = home[['DEFLECTIONS_DIFF', 'CONTEST_RATE', 'CONTEST_RATE_2', 'CONTEST_RATE_3', 'CHARGES_DIFF', 'SCREEN_AST_DIFF', 'SCREEN_AST_PTS_DIFF', 'LOOSE_DIFFERENCE', 'OFF_BOXOUT_DIFF', 'DEF_BOXOUT_DIFF', 'BOXOUT_TM_RBS_DIFF']].values\n",
    "y_hd = home['WINNER'].values\n",
    "\n",
    "X_hd_train, X_hd_test, y_hd_train, y_hd_test = train_test_split(X_hd, y_hd, stratify = y_hd, random_state = 858, test_size = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ad = away[['DEFLECTIONS_DIFF', 'CONTEST_RATE', 'CONTEST_RATE_2', 'CONTEST_RATE_3', 'CHARGES_DIFF', 'SCREEN_AST_DIFF', 'SCREEN_AST_PTS_DIFF', 'LOOSE_DIFFERENCE', 'OFF_BOXOUT_DIFF', 'DEF_BOXOUT_DIFF', 'BOXOUT_TM_RBS_DIFF']].values\n",
    "y_ad = away['WINNER'].values\n",
    "\n",
    "X_ad_train, X_ad_test, y_ad_train, y_ad_test = train_test_split(X_ad, y_ad, stratify = y_ad, random_state = 858, test_size = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'xgb__learning_rate': [.05, .1, .15],\n",
    "              'xgb__max_depth': [2, 3, 4],\n",
    "              'xgb__n_estimators': [19, 20, 21, 22, 23],\n",
    "              'xgb__subsample': [.4, .5, .6],\n",
    "              'xgb__use_label_encoder': [False],\n",
    "              'xgb__eval_metric': ['logloss']}\n",
    "\n",
    "modXGB = Pipeline([('xgb', XGBClassifier())])\n",
    "\n",
    "gs = GridSearchCV(estimator = modXGB, param_grid = param_grid, cv = 5)\n",
    "gs.fit(X_hr_train, y_hr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit XGBClassifier with tuned parameters\n",
    "xgb = Pipeline([('xgb', XGBClassifier(\n",
    "    learning_rate = gs.best_params_['xgb__learning_rate'],\n",
    "    max_depth = gs.best_params_['xgb__max_depth'], \n",
    "    n_estimators = gs.best_params_['xgb__n_estimators'],\n",
    "    subsample = gs.best_params_['xgb__subsample'],\n",
    "    use_label_encoder = gs.best_params_['xgb__use_label_encoder'],\n",
    "    eval_metric = gs.best_params_['xgb__eval_metric']))])\n",
    "\n",
    "xgb.fit(X_hr_train, y_hr_train)\n",
    "\n",
    "# Predictions and predicted probabilities for training set\n",
    "xgb_hr_train = xgb.predict(X_hr_train)\n",
    "xgb_hr_train_prob = xgb.predict_proba(X_hr_train)[:,1]\n",
    "\n",
    "# Predictions and predicted probabilities for test set\n",
    "xgb_hr_test = xgb.predict(X_hr_test)\n",
    "xgb_hr_test_prob = xgb.predict_proba(X_hr_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.59      0.67       696\n",
      "           1       0.74      0.88      0.80       921\n",
      "\n",
      "    accuracy                           0.75      1617\n",
      "   macro avg       0.76      0.73      0.74      1617\n",
      "weighted avg       0.76      0.75      0.74      1617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_hr_train, xgb_hr_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.41      0.46       298\n",
      "           1       0.62      0.73      0.67       395\n",
      "\n",
      "    accuracy                           0.59       693\n",
      "   macro avg       0.57      0.57      0.56       693\n",
      "weighted avg       0.58      0.59      0.58       693\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_hr_test, xgb_hr_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'xgb__learning_rate': [.05, .1, .15],\n",
    "              'xgb__max_depth': [2, 3, 4],\n",
    "              'xgb__n_estimators': [19, 20, 21, 22, 23],\n",
    "              'xgb__subsample': [.4, .5, .6],\n",
    "              'xgb__use_label_encoder': [False],\n",
    "              'xgb__eval_metric': ['logloss']}\n",
    "\n",
    "modXGB = Pipeline([('xgb', XGBClassifier())])\n",
    "\n",
    "gs = GridSearchCV(estimator = modXGB, param_grid = param_grid, cv = 5)\n",
    "gs.fit(X_ar_train, y_ar_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit XGBClassifier with tuned parameters\n",
    "xgb = Pipeline([('xgb', XGBClassifier(\n",
    "    learning_rate = gs.best_params_['xgb__learning_rate'],\n",
    "    max_depth = gs.best_params_['xgb__max_depth'], \n",
    "    n_estimators = gs.best_params_['xgb__n_estimators'],\n",
    "    subsample = gs.best_params_['xgb__subsample'],\n",
    "    use_label_encoder = gs.best_params_['xgb__use_label_encoder'],\n",
    "    eval_metric = gs.best_params_['xgb__eval_metric']))])\n",
    "\n",
    "xgb.fit(X_ar_train, y_ar_train)\n",
    "\n",
    "# Predictions and predicted probabilities for training set\n",
    "xgb_ar_train = xgb.predict(X_ar_train)\n",
    "xgb_ar_train_prob = xgb.predict_proba(X_ar_train)[:,1]\n",
    "\n",
    "# Predictions and predicted probabilities for test set\n",
    "xgb_ar_test = xgb.predict(X_ar_test)\n",
    "xgb_ar_test_prob = xgb.predict_proba(X_ar_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.86      0.80       921\n",
      "           1       0.77      0.61      0.68       696\n",
      "\n",
      "    accuracy                           0.75      1617\n",
      "   macro avg       0.76      0.73      0.74      1617\n",
      "weighted avg       0.75      0.75      0.75      1617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_ar_train, xgb_ar_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.76      0.69       395\n",
      "           1       0.58      0.44      0.50       298\n",
      "\n",
      "    accuracy                           0.62       693\n",
      "   macro avg       0.61      0.60      0.60       693\n",
      "weighted avg       0.61      0.62      0.61       693\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_ar_test, xgb_ar_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'xgb__learning_rate': [.05, .1, .15],\n",
    "              'xgb__max_depth': [2, 3, 4],\n",
    "              'xgb__n_estimators': [19, 20, 21, 22, 23],\n",
    "              'xgb__subsample': [.4, .5, .6],\n",
    "              'xgb__use_label_encoder': [False],\n",
    "              'xgb__eval_metric': ['logloss']}\n",
    "\n",
    "modXGB = Pipeline([('xgb', XGBClassifier())])\n",
    "\n",
    "gs = GridSearchCV(estimator = modXGB, param_grid = param_grid, cv = 5)\n",
    "gs.fit(X_hd_train, y_hd_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit XGBClassifier with tuned parameters\n",
    "xgb = Pipeline([('xgb', XGBClassifier(\n",
    "    learning_rate = gs.best_params_['xgb__learning_rate'],\n",
    "    max_depth = gs.best_params_['xgb__max_depth'], \n",
    "    n_estimators = gs.best_params_['xgb__n_estimators'],\n",
    "    subsample = gs.best_params_['xgb__subsample'],\n",
    "    use_label_encoder = gs.best_params_['xgb__use_label_encoder'],\n",
    "    eval_metric = gs.best_params_['xgb__eval_metric']))])\n",
    "\n",
    "xgb.fit(X_hd_train, y_hd_train)\n",
    "\n",
    "# Predictions and predicted probabilities for training set\n",
    "xgb_hd_train = xgb.predict(X_hd_train)\n",
    "xgb_hd_train_prob = xgb.predict_proba(X_hd_train)[:,1]\n",
    "\n",
    "# Predictions and predicted probabilities for test set\n",
    "xgb_hd_test = xgb.predict(X_hd_test)\n",
    "xgb_hd_test_prob = xgb.predict_proba(X_hd_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.57      0.65       696\n",
      "           1       0.72      0.86      0.79       921\n",
      "\n",
      "    accuracy                           0.73      1617\n",
      "   macro avg       0.74      0.71      0.72      1617\n",
      "weighted avg       0.74      0.73      0.73      1617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_hd_train, xgb_hd_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.39      0.44       298\n",
      "           1       0.61      0.72      0.66       395\n",
      "\n",
      "    accuracy                           0.58       693\n",
      "   macro avg       0.56      0.55      0.55       693\n",
      "weighted avg       0.57      0.58      0.56       693\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_hd_test, xgb_hd_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'xgb__learning_rate': [.05, .1, .15],\n",
    "              'xgb__max_depth': [2, 3, 4],\n",
    "              'xgb__n_estimators': [19, 20, 21, 22, 23],\n",
    "              'xgb__subsample': [.4, .5, .6],\n",
    "              'xgb__use_label_encoder': [False],\n",
    "              'xgb__eval_metric': ['logloss']}\n",
    "\n",
    "modXGB = Pipeline([('xgb', XGBClassifier())])\n",
    "\n",
    "gs = GridSearchCV(estimator = modXGB, param_grid = param_grid, cv = 5)\n",
    "gs.fit(X_ad_train, y_ad_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit XGBClassifier with tuned parameters\n",
    "xgb = Pipeline([('xgb', XGBClassifier(\n",
    "    learning_rate = gs.best_params_['xgb__learning_rate'],\n",
    "    max_depth = gs.best_params_['xgb__max_depth'], \n",
    "    n_estimators = gs.best_params_['xgb__n_estimators'],\n",
    "    subsample = gs.best_params_['xgb__subsample'],\n",
    "    use_label_encoder = gs.best_params_['xgb__use_label_encoder'],\n",
    "    eval_metric = gs.best_params_['xgb__eval_metric']))])\n",
    "\n",
    "xgb.fit(X_hd_train, y_hd_train)\n",
    "\n",
    "# Predictions and predicted probabilities for training set\n",
    "xgb_ad_train = xgb.predict(X_ad_train)\n",
    "xgb_ad_train_prob = xgb.predict_proba(X_ad_train)[:,1]\n",
    "\n",
    "# Predictions and predicted probabilities for test set\n",
    "xgb_ad_test = xgb.predict(X_ad_test)\n",
    "xgb_ad_test_prob = xgb.predict_proba(X_ad_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.41      0.52       921\n",
      "           1       0.50      0.78      0.61       696\n",
      "\n",
      "    accuracy                           0.57      1617\n",
      "   macro avg       0.60      0.59      0.56      1617\n",
      "weighted avg       0.62      0.57      0.55      1617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_ad_train, xgb_ad_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.38      0.49       395\n",
      "           1       0.49      0.78      0.60       298\n",
      "\n",
      "    accuracy                           0.55       693\n",
      "   macro avg       0.59      0.58      0.54       693\n",
      "weighted avg       0.60      0.55      0.54       693\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_ad_test, xgb_ad_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier().fit(X_hr_train, y_hr_train)\n",
    "\n",
    "# Predictions and predicted probabilities for training set\n",
    "gb_hr_train = gb.predict(X_hr_train)\n",
    "gb_hr_train_prob = gb.predict_proba(X_hr_train)[:,1]\n",
    "\n",
    "# Predictions and predicted probabilities for test set\n",
    "gb_hr_test = gb.predict(X_hr_test)\n",
    "gb_hr_test_prob = gb.predict_proba(X_hr_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.65      0.72       696\n",
      "           1       0.77      0.90      0.83       921\n",
      "\n",
      "    accuracy                           0.79      1617\n",
      "   macro avg       0.80      0.77      0.78      1617\n",
      "weighted avg       0.79      0.79      0.78      1617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_hr_train, gb_hr_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.40      0.46       298\n",
      "           1       0.62      0.73      0.67       395\n",
      "\n",
      "    accuracy                           0.59       693\n",
      "   macro avg       0.58      0.57      0.57       693\n",
      "weighted avg       0.58      0.59      0.58       693\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_hr_test, gb_hr_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier().fit(X_ar_train, y_ar_train)\n",
    "\n",
    "# Predictions and predicted probabilities for training set\n",
    "gb_ar_train = gb.predict(X_ar_train)\n",
    "gb_ar_train_prob = gb.predict_proba(X_ar_train)[:,1]\n",
    "\n",
    "# Predictions and predicted probabilities for test set\n",
    "gb_ar_test = gb.predict(X_ar_test)\n",
    "gb_ar_test_prob = gb.predict_proba(X_ar_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.92      0.84       921\n",
      "           1       0.86      0.66      0.74       696\n",
      "\n",
      "    accuracy                           0.80      1617\n",
      "   macro avg       0.82      0.79      0.79      1617\n",
      "weighted avg       0.81      0.80      0.80      1617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_ar_train, gb_ar_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.77      0.69       395\n",
      "           1       0.57      0.41      0.48       298\n",
      "\n",
      "    accuracy                           0.61       693\n",
      "   macro avg       0.60      0.59      0.58       693\n",
      "weighted avg       0.61      0.61      0.60       693\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_ar_test, gb_ar_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier().fit(X_hd_train, y_hd_train)\n",
    "\n",
    "# Predictions and predicted probabilities for training set\n",
    "gb_hd_train = gb.predict(X_hd_train)\n",
    "gb_hd_train_prob = gb.predict_proba(X_hd_train)[:,1]\n",
    "\n",
    "# Predictions and predicted probabilities for test set\n",
    "gb_hd_test = gb.predict(X_hd_test)\n",
    "gb_hd_test_prob = gb.predict_proba(X_hd_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.61      0.69       696\n",
      "           1       0.75      0.89      0.81       921\n",
      "\n",
      "    accuracy                           0.77      1617\n",
      "   macro avg       0.78      0.75      0.75      1617\n",
      "weighted avg       0.77      0.77      0.76      1617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_hd_train, gb_hd_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.38      0.44       298\n",
      "           1       0.62      0.76      0.68       395\n",
      "\n",
      "    accuracy                           0.59       693\n",
      "   macro avg       0.58      0.57      0.56       693\n",
      "weighted avg       0.58      0.59      0.58       693\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_hd_test, gb_hd_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier().fit(X_ad_train, y_ad_train)\n",
    "\n",
    "# Predictions and predicted probabilities for training set\n",
    "gb_ad_train = gb.predict(X_ad_train)\n",
    "gb_ad_train_prob = gb.predict_proba(X_ad_train)[:,1]\n",
    "\n",
    "# Predictions and predicted probabilities for test set\n",
    "gb_ad_test = gb.predict(X_ad_test)\n",
    "gb_ad_test_prob = gb.predict_proba(X_ad_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.90      0.82       921\n",
      "           1       0.82      0.59      0.69       696\n",
      "\n",
      "    accuracy                           0.77      1617\n",
      "   macro avg       0.78      0.75      0.75      1617\n",
      "weighted avg       0.78      0.77      0.76      1617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_ad_train, gb_ad_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.76      0.68       395\n",
      "           1       0.53      0.36      0.43       298\n",
      "\n",
      "    accuracy                           0.59       693\n",
      "   macro avg       0.57      0.56      0.55       693\n",
      "weighted avg       0.58      0.59      0.57       693\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_ad_test, gb_ad_test))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bd6147c3f48b1be6735c4954100e2a61ae3f6cac3ef15585b7c3a6f1aa3af2f2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
