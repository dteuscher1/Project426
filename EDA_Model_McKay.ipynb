{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from plotnine import ggplot, geom_line, aes, labs, theme_minimal, geom_boxplot, coord_flip\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "# conda install -c conda-forge plotnine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4620, 25)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = pd.read_csv('model_data.csv')\n",
    "dat['WINNER_cat'] = dat['WINNER'].astype('category')\n",
    "dat.columns\n",
    "dat.head()\n",
    "dat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf(X_train, X_test, y_train, y_test):\n",
    "    mod = RandomForestClassifier(random_state = 426)\n",
    "    param_grid_={'n_estimators': [100,500,1000], # number of trees in the forest\n",
    "             'criterion': [\"gini\", \"entropy\"],\n",
    "             'max_depth': [3, 5, 7],     # max number of layers\n",
    "             'min_samples_leaf': [1, 10]}\n",
    "    gs = GridSearchCV(mod, param_grid, scoring='accuracy',cv = 3)\n",
    "    rf_fit = gs.fit(X_train, y_train)\n",
    "    \n",
    "    train_preds = rf_fit.predict(X_train)\n",
    "    train_preds_probs = rf_fit.predict_proba(X_train)\n",
    "    \n",
    "    test_preds = rf_fit.predict(X_test)\n",
    "    test_preds_probs = rf_fit.predict_proba(X_test)\n",
    "    return train_preds, train_preds_probs, test_preds, test_preds_probs, gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Home Ratio\n",
    "# 2 - Away Ratio\n",
    "# 3 - Home Diff\n",
    "# 4 - Away Diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "away = dat.iloc[::2]\n",
    "home = dat.iloc[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_a = away['WINNER'].values\n",
    "X_ar = away[['DEFLECTIONS_RATIO', 'CONTEST_RATE', 'CONTEST_RATE_2', 'CONTEST_RATE_3', 'CHARGES_RATIO', 'SCREEN_AST_RATIO', 'SCREEN_AST_PTS_RATIO', 'LOOSE_RATIO', 'OFF_BOXOUT_RATIO', 'DEF_BOXOUT_RATIO', 'BOXOUT_TM_RBS_RATIO']].values\n",
    "y_h = home['WINNER'].values\n",
    "X_hr = home[['DEFLECTIONS_RATIO', 'CONTEST_RATE', 'CONTEST_RATE_2', 'CONTEST_RATE_3', 'CHARGES_RATIO', 'SCREEN_AST_RATIO', 'SCREEN_AST_PTS_RATIO', 'LOOSE_RATIO', 'OFF_BOXOUT_RATIO', 'DEF_BOXOUT_RATIO', 'BOXOUT_TM_RBS_RATIO']].values\n",
    "X_ad = away[['DEFLECTIONS_DIFF', 'CONTEST_RATE', 'CONTEST_RATE_2', 'CONTEST_RATE_3', 'CHARGES_DIFF', 'SCREEN_AST_DIFF', 'SCREEN_AST_PTS_DIFF', 'LOOSE_DIFFERENCE', 'OFF_BOXOUT_DIFF', 'DEF_BOXOUT_DIFF', 'BOXOUT_TM_RBS_DIFF']].values\n",
    "X_hd = home[['DEFLECTIONS_DIFF', 'CONTEST_RATE', 'CONTEST_RATE_2', 'CONTEST_RATE_3', 'CHARGES_DIFF', 'SCREEN_AST_DIFF', 'SCREEN_AST_PTS_DIFF', 'LOOSE_DIFFERENCE', 'OFF_BOXOUT_DIFF', 'DEF_BOXOUT_DIFF', 'BOXOUT_TM_RBS_DIFF']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X_ar, y_a, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     mod = RandomForestClassifier(random_state = 426)\n",
    "#     param_grid={'n_estimators': [100,500,1000], # number of trees in the forest\n",
    "#              'criterion': [\"gini\", \"entropy\"],\n",
    "#              'max_depth': [3, 5, 7],     # max number of layers\n",
    "#              'min_samples_leaf': [1, 10]}\n",
    "#     gs = GridSearchCV(mod, param_grid, scoring='accuracy',cv = 3)\n",
    "#     rf_fit = gs.fit(X_train, y_train)\n",
    "    \n",
    "#     train_preds = rf_fit.predict(X_train)\n",
    "#     train_preds_probs = rf_fit.predict_proba(X_train)\n",
    "    \n",
    "#     test_preds = rf_fit.predict(X_test)\n",
    "#     test_preds_probs = rf_fit.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'n_estimators': 500}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.mean(train_preds == y_train)\n",
    "# np.mean(test_preds == y_test)\n",
    "# gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Home Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hr_train, X_hr_test, y_hr_train, y_hr_test = train_test_split(X_hr, y_h, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hr_train_preds, X_hr_train_probs, X_hr_test_preds, X_hr_test_probs, hr_best_parms = rf(X_hr_train, X_hr_test, y_hr_train, y_hr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'n_estimators': 1000}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_best_parms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7034632034632035\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.53      0.61       806\n",
      "           1       0.70      0.83      0.76      1042\n",
      "\n",
      "   micro avg       0.70      0.70      0.70      1848\n",
      "   macro avg       0.71      0.68      0.69      1848\n",
      "weighted avg       0.71      0.70      0.70      1848\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(X_hr_train_preds == y_hr_train))\n",
    "print(metrics.classification_report(y_hr_train, X_hr_train_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6038961038961039\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.39      0.45       188\n",
      "           1       0.64      0.75      0.69       274\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       462\n",
      "   macro avg       0.58      0.57      0.57       462\n",
      "weighted avg       0.59      0.60      0.59       462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(X_hr_test_preds == y_hr_test))\n",
    "print(metrics.classification_report(y_hr_test, X_hr_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Away Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ar_train, X_ar_test, y_ar_train, y_ar_test = train_test_split(X_ar, y_a, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ar_train_preds, X_ar_train_probs, X_ar_test_preds, X_ar_test_probs, ar_best_parms = rf(X_ar_train, X_ar_test, y_ar_train, y_ar_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'n_estimators': 500}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_best_parms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7278138528138528\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.88      0.79      1042\n",
      "           1       0.78      0.52      0.63       806\n",
      "\n",
      "   micro avg       0.73      0.73      0.73      1848\n",
      "   macro avg       0.74      0.70      0.71      1848\n",
      "weighted avg       0.74      0.73      0.72      1848\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(X_ar_train_preds == y_ar_train))\n",
    "print(metrics.classification_report(y_ar_train, X_ar_train_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6168831168831169\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.76      0.70       274\n",
      "           1       0.54      0.40      0.46       188\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       462\n",
      "   macro avg       0.60      0.58      0.58       462\n",
      "weighted avg       0.61      0.62      0.60       462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(X_ar_test_preds == y_ar_test))\n",
    "print(metrics.classification_report(y_ar_test, X_ar_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Home Diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hd_train, X_hd_test, y_hd_train, y_hd_test = train_test_split(X_hd, y_h, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hd_train_preds, X_hd_train_probs, X_hd_test_preds, X_hd_test_probs, hd_best_parms = rf(X_hd_train, X_hd_test, y_hd_train, y_hd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 7,\n",
       " 'min_samples_leaf': 1,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hd_best_parms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7792207792207793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.60      0.70       806\n",
      "           1       0.75      0.91      0.82      1042\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      1848\n",
      "   macro avg       0.80      0.76      0.76      1848\n",
      "weighted avg       0.79      0.78      0.77      1848\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(X_hd_train_preds == y_hd_train))\n",
    "print(metrics.classification_report(y_hd_train, X_hd_train_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5952380952380952\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.36      0.42       188\n",
      "           1       0.63      0.76      0.69       274\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       462\n",
      "   macro avg       0.57      0.56      0.55       462\n",
      "weighted avg       0.58      0.60      0.58       462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(X_hd_test_preds == y_hd_test))\n",
    "print(metrics.classification_report(y_hd_test, X_hd_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Away Diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ad_train, X_ad_test, y_ad_train, y_ad_test = train_test_split(X_ad, y_a, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ad_train_preds, X_ad_train_probs, X_ad_test_preds, X_ad_test_probs, ad_best_parms = rf(X_ad_train, X_ad_test, y_ad_train, y_ad_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 7,\n",
       " 'min_samples_leaf': 10,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad_best_parms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7418831168831169\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.90      0.80      1042\n",
      "           1       0.81      0.54      0.64       806\n",
      "\n",
      "   micro avg       0.74      0.74      0.74      1848\n",
      "   macro avg       0.76      0.72      0.72      1848\n",
      "weighted avg       0.76      0.74      0.73      1848\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(X_ad_train_preds == y_ad_train))\n",
    "print(metrics.classification_report(y_ad_train, X_ad_train_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5909090909090909\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69       274\n",
      "           1       0.50      0.35      0.41       188\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       462\n",
      "   macro avg       0.56      0.55      0.55       462\n",
      "weighted avg       0.57      0.59      0.57       462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(X_ad_test_preds == y_ad_test))\n",
    "print(metrics.classification_report(y_ad_test, X_ad_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
